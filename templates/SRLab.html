<div class="row">
    <div class="text-center" style="color:#00543c"><h1>Single Image Super-resolution from self-similarity</h1></div>
</div>

<div class="row">
    <div class="text-center" style="color:#FDBB30"><em><h3>by Shaofeng Chen</h3></em></div>
</div>
<div class="container">
    <div class="row" id="content" data-spy="scroll">
        <div class="col-sm-2">
            <nav class="hidden-xs" id="contentBar">
                <ul class="nav nav-pills nav-stacked affix" data-spy="affix">
                    <li><a class="nav-item" href="#introduction">Introduction</a></li>
                    <li><a class="nav-item" href="#algorithmDetail">Algorithm Detail</a></li>
                    <li><a class="nav-item" href="#experiments">Experiments</a></li>
                </ul>
            </nav>
        </div>

        <div class="col-sm-8 col-md-offset-0 col-sm-offset-1" id="introduction">
            <h3>Introduction</h3>
            <p>
                The goal of single image super resolution(SR) is to estimate a sharp high-resolution image from a low
                resolution input image. Traditionally, there exits two categories of image SR algorithms.
                One is to combine series of low-resolution images taken from the same scene with subpixel alignment to
                reconstruct the mutual high-resolution image. Another category falls into reconstructing the high-resolution
                image from just one singe low-resolution image with or without example database. Image super-resolution
                offers the promise to overcome some inherent limitations of low-cost imaging devices such as cell phones and
                surveillance cameras, and has been proved to be essential in medical and satellite imaging where higher
                resolution images can improve the accuracy of diagnosis. Meanwhile, image SR can enhance the utilization of
                high resolution display devices such as high-definition LCDs, and it provides a low-cost and feasible way
                to convert standard-definition TV to HDTV.
            </p>
        </div>

        <div class="col-md-offset-2 col-sm-offset-3 col-sm-8" id="algorithmDetail">
            <h3>Algorithm Detail</h3>
            <p>
                My experiments focused on single image super-resolution.
                I exploit the self-example recurrence across image scales to construct the low-resolution and corresponding
                high-resolution image dictionary which describes the co-occurrence between low-resolution and high-resolution
                image patches, and thus avoid large database of training images. In addition, from the standpoint of image
                statistics and compressive sensing, each high-resolution image patch can be perfectly reconstructed by the
                sparse representation of its low-resolution counterpart. In the following part, I will firstly describe the
                construction of low-resolution and high-resolution image dictionary, and then I will show how each high-resolution
                patch can be reconstructed based on this dictionary and inspiration I got from sparse representation.
                Finally, several experimental results will be demonstrated and compared to state of the art.
                Firstly, I construct a image pyramid using the imaging model with the subsampling factor of 1.25:<br>
                <span id="formula1">
                    <img src="images/SRLab/formula1.gif"/>
                </span><br>
                Here, X stands for the original high-resolution image, and Y is the burred and subsampled low-resolution
                image simulating the imaging process of real imaging devices. H represents the blurring kernel and D is the
                subsampling operator. An example of this kind of image pyramid is illustrated in figure 1
                <div class="text-center" id="figure1">
                    <div class="figures">
                        <span class="image">
                            <img src="images/SRLab/figure1-0.jpg"/>
                        </span>
                        <span class="image">
                            <img src="images/SRLab/figure1-1.jpg"/>
                        </span>
                        <span class="image">
                            <img src="images/SRLab/figure1-2.jpg"/>
                        </span>
                        <span class="image">
                            <img src="images/SRLab/figure1-3.jpg"/>
                        </span>
                        <span class="image">
                            <img src="images/SRLab/figure1-4.jpg"/>
                        </span>
                        <span class="image">
                            <img src="images/SRLab/figure1-5.jpg"/>
                        </span>
                    </div>
                    <div class="figureFooter">Figure 1. Low resolution image pyramid.</div>

                </div>
                Each image of the pyramid is then upsampled to the original scale as the source low-resolution image and serves
                as the low-resolution training images. Meanwhile, there mutual high-resolution counterparts were chosen to be
                the original low-resolution input image. Based on this low-resolution / high-resolution image pairs, the
                low-resolution / high-resolution dictionary can be constructed by the process illustrated in figure 2.
                <div class="text-center" id="figure2">
                    <div class="image"><img width="369" height="376" src="images/SRLab/figure2.jpg"></div>
                    <div class="figureFooter">Figure 2. Flow chart of low-res/high-res dictionary construction.</div>
                </div>
                Where
                <span id="formula2">
                    <img src="images/SRLab/formula2.gif"/>
                </span>
                represents the low-resolution images from the image pyramid and
                <span id="formula3">
                    <img src="images/SRLab/formula3.gif"/>
                </span>
                stands for their corresponding high-resolution images. After finishing the dictionary construction,
                I then reconstruct each patch in the high-resolution image by raster-scan order. As I mentioned earlier,
                each low-resolution patch y of the source input image can be represented as a sparse representation with
                respect to the low-resolution dictionary
                <span id="formula4">
                    <img src="images/SRLab/formula4.gif"/>
                </span>
                . Then the reconstruction of its high resolution version x can be solved by minimizing the following term:<br>
                <span id="formula5">
                    <img src="images/SRLab/formula5.gif"/>
                </span><br>
                Where
                <span id="formula6">
                    <img src="images/SRLab/formula6.gif"/>
                </span>
                gives the sparse representation of <em>y</em> with respect to
                <span>
                    <img src="images/SRLab/formula4.gif"/>
                </span>
                .Thus, using this sparsest coefficient
                <span id="formula7">
                    <img src="images/SRLab/formula7.gif"/>
                </span>
                , the high-resolution counterpart of <em>y</em> can be reconstructed as:<br>
                <span id="formula8">
                    <img src="images/SRLab/formula8.gif"/>
                </span>
            </p>
        </div>

    </div>
</div>
